╔══════════════════════════════════════════════════════════════════════╗
║              🔄 FIX DUPLICATES - ШПАРГАЛКА                           ║
╚══════════════════════════════════════════════════════════════════════╝

📁 РАСПОЛОЖЕНИЕ: scripts/migrations/fix_duplicates.py

┌─────────────────────────────────────────────────────────────────────┐
│ 🚀 БЫСТРЫЙ СТАРТ                                                    │
└─────────────────────────────────────────────────────────────────────┘

# Запустить скрипт
python scripts/migrations/fix_duplicates.py

# Скрипт покажет дубликаты и попросит подтверждение
# Введите "yes" для удаления

┌─────────────────────────────────────────────────────────────────────┐
│ 🔍 КАК НАХОДИТ ДУБЛИКАТЫ                                            │
└─────────────────────────────────────────────────────────────────────┘

Дубликаты = одинаковые:
  ✓ title (название, без учета регистра)
  ✓ creator (автор/исполнитель, без учета регистра)
  ✓ type (book/movie/music)

Пример:
  "Inception" by "Christopher Nolan" (movie)
  "inception" by "christopher nolan" (movie)
  → ЭТО ДУБЛИКАТЫ ✅

┌─────────────────────────────────────────────────────────────────────┐
│ 🎯 КАК ВЫБИРАЕТ ЛУЧШУЮ ВЕРСИЮ                                       │
└─────────────────────────────────────────────────────────────────────┘

СИСТЕМА ОЦЕНКИ КАЧЕСТВА (0-10 баллов):

  +1 балл за каждое заполненное поле:
    - description
    - image_url
    - year
    - rating (только для фильмов)
    - mood
    - genre
    - epoch
  
  +2 балла: есть AI-описание (needs_ai = 0)
  +1 балл: есть source_id (ID из API)

ОСТАВЛЯЕТ запись с МАКСИМАЛЬНЫМ качеством
УДАЛЯЕТ все остальные копии

Пример:
  ID 1234: качество 8/10 ✅ ОСТАВИТЬ
  ID 5678: качество 6/10 ❌ УДАЛИТЬ
  ID 9012: качество 5/10 ❌ УДАЛИТЬ

┌─────────────────────────────────────────────────────────────────────┐
│ ✅ ЧТО ДЕЛАЕТ СКРИПТ                                                │
└─────────────────────────────────────────────────────────────────────┘

1. Создает backup БД
2. Ищет дубликаты (одинаковые title+creator+type)
3. Оценивает качество каждого дубликата
4. Показывает детальную информацию
5. Просит подтверждение
6. Удаляет худшие версии
7. Оставляет лучшую версию
8. Создает JSON отчет
9. Показывает статистику

┌─────────────────────────────────────────────────────────────────────┐
│ 📊 ПРИМЕР ВЫВОДА                                                    │
└─────────────────────────────────────────────────────────────────────┘

🔍 ПОИСК ДУБЛИКАТОВ
Найдено групп дубликатов: 5

📋 ДЕТАЛЬНАЯ ИНФОРМАЦИЯ:

1. 🎬 'Inception'
   Тип: movie | Копий: 3
   
   1. ID 1234 - Качество: 8/10 - ✅ ОСТАВИТЬ
      Описание: Yes | Изображение: Yes | Год: 2010
   
   2. ID 5678 - Качество: 6/10 - ❌ УДАЛИТЬ
      Описание: No | Изображение: Yes | Год: 2010
   
   3. ID 9012 - Качество: 5/10 - ❌ УДАЛИТЬ
      Описание: No | Изображение: No | Год: 2010

⚠️  ВНИМАНИЕ!
   Найдено 5 групп дубликатов
   Будет удалено записей: 8
   Будет оставлено лучших версий: 5

❓ Продолжить удаление? (yes/no): yes

🧹 УДАЛЕНИЕ ДУБЛИКАТОВ
✅ Удалено записей: 8
✅ Оставлено лучших версий: 5

┌─────────────────────────────────────────────────────────────────────┐
│ 💾 ВОССТАНОВЛЕНИЕ ИЗ BACKUP                                         │
└─────────────────────────────────────────────────────────────────────┘

# Найти последний backup
ls -lt backups/

# Восстановить
cp backups/content_backup_YYYYMMDD_HHMMSS.db content.db

# Проверить
python scripts/tools/db_inspector.py --duplicates

┌─────────────────────────────────────────────────────────────────────┐
│ 📄 ОТЧЕТ О УДАЛЕННЫХ ЗАПИСЯХ                                        │
└─────────────────────────────────────────────────────────────────────┘

Сохраняется в: reports/duplicates_removed_YYYYMMDD_HHMMSS.json

Содержит:
  - Timestamp удаления
  - Список удаленных записей
  - ID записи, которая была оставлена вместо них
  - Статистику (сколько было/стало)

┌─────────────────────────────────────────────────────────────────────┐
│ 🔧 ПРОВЕРКА РЕЗУЛЬТАТОВ                                             │
└─────────────────────────────────────────────────────────────────────┘

# Полная статистика
python scripts/tools/db_inspector.py

# Проверка дубликатов (должно быть 0)
python scripts/tools/db_inspector.py --duplicates

# SQL проверка
sqlite3 content.db "
  SELECT title, creator, type, COUNT(*) 
  FROM content 
  GROUP BY LOWER(title), LOWER(creator), type 
  HAVING COUNT(*) > 1
"

Ожидаемый результат:
  Дубликаты не найдены! ✅

┌─────────────────────────────────────────────────────────────────────┐
│ 🎯 ПРЕДОТВРАЩЕНИЕ ДУБЛИКАТОВ В БУДУЩЕМ                              │
└─────────────────────────────────────────────────────────────────────┘

1️⃣ Добавьте UNIQUE constraint на source_id:
   CREATE UNIQUE INDEX idx_source_id ON content(source_id);

2️⃣ Обновите скрипты сбора (harvest_*.py):

   # Проверяйте перед вставкой
   cursor.execute("""
     SELECT id FROM content 
     WHERE source_id = ? AND type = ?
   """, (api_id, content_type))
   
   if cursor.fetchone():
     # Обновить существующую запись
     UPDATE ...
   else:
     # Создать новую
     INSERT ...

3️⃣ Используйте INSERT OR REPLACE:
   INSERT OR REPLACE INTO content (source_id, ...)
   VALUES (?, ...)

┌─────────────────────────────────────────────────────────────────────┐
│ 🐛 TROUBLESHOOTING                                                  │
└─────────────────────────────────────────────────────────────────────┘

❌ "Найдено 0 дубликатов" (но вы уверены что они есть)
   → Проверьте регистр: sqlite3 content.db "SELECT DISTINCT title FROM content"
   → Скрипт ищет по LOWER(title)

❌ Удалилась не та запись
   → Откатите из backup
   → Проверьте QUALITY_FIELDS в скрипте
   → Возможно нужно скорректировать систему оценки

❌ "Permission denied" при создании отчета
   → mkdir -p reports && chmod 755 reports

❌ Хочу откатить все изменения
   → cp backups/content_backup_LATEST.db content.db

┌─────────────────────────────────────────────────────────────────────┐
│ 📝 WORKFLOW ПОСЛЕ УДАЛЕНИЯ                                          │
└─────────────────────────────────────────────────────────────────────┘

1️⃣ Проверить результаты:
   python scripts/tools/db_inspector.py

2️⃣ Обновить скрипты сбора:
   - harvest_books.py: проверка по ISBN
   - harvest_movies.py: проверка по TMDB ID
   - harvest_music.py: проверка по Spotify Track ID

3️⃣ Запустить AI Describer:
   python scripts/tools/ai_describer.py --limit=100

4️⃣ Добавить UNIQUE constraint:
   sqlite3 content.db "CREATE UNIQUE INDEX idx_source_id ON content(source_id)"

┌─────────────────────────────────────────────────────────────────────┐
│ 🎓 BEST PRACTICES                                                   │
└─────────────────────────────────────────────────────────────────────┘

✓ Запускайте перед каждым деплоем
✓ Проверяйте дубликаты раз в неделю
✓ Сохраняйте отчеты для аудита
✓ Всегда проверяйте backup перед запуском
✓ Обновите скрипты сбора для предотвращения
✓ Используйте source_id как UNIQUE ключ

┌─────────────────────────────────────────────────────────────────────┐
│ 📊 СТАТИСТИКА ПО ВАШЕЙ БД                                           │
└─────────────────────────────────────────────────────────────────────┘

Согласно последнему отчету:
  Всего записей: 11,215
  Групп дубликатов: 5
  Будет удалено: ~8-10 записей
  Очистка: ~0.07% базы

Это ОТЛИЧНО! Очень мало дубликатов 👍

╔══════════════════════════════════════════════════════════════════════╗
║  📞 Поддержка: github.com/your-repo/issues                          ║
║  📚 Полная документация: FIX_DUPLICATES_README.md                   ║
║  🎉 Версия: 1.0 | Январь 2025                                       ║
╚══════════════════════════════════════════════════════════════════════╝
