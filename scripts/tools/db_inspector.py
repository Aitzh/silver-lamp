#!/usr/bin/env python3
"""
üîç DB INSPECTOR - –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
–í–µ—Ä—Å–∏—è: 2.0
–ê–≤—Ç–æ—Ä: Coffee Books AI Team

–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- –ü–æ–ª–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞
- –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –ø–æ–ª—è, –¥—É–±–ª–∏–∫–∞—Ç—ã)
- –ü—Ä–æ–≤–µ—Ä–∫–∞ integrity (—É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å, –≤–∞–ª–∏–¥–∞—Ü–∏—è)
- –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–æ–≤ –≤ JSON/CSV
- –ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
"""

import sqlite3
import argparse
import json
import csv
import sys
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Tuple

# ==================== –ö–û–ù–°–¢–ê–ù–¢–´ ====================

DB_PATH = 'content.db'

EMOJI_MAP = {
    'book': 'üìñ',
    'movie': 'üé¨',
    'music': 'üéµ'
}

# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
REQUIRED_FIELDS = {
    'book': ['title', 'creator', 'genre'],
    'movie': ['title', 'year', 'genre'],
    'music': ['title', 'creator', 'genre']
}

# ==================== –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° ====================

class DatabaseInspector:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∏–Ω—Å–ø–µ–∫—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, db_path: str = DB_PATH):
        self.db_path = db_path
        self.conn = None
        self.cursor = None
        self.stats = {}
        
    def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.conn = sqlite3.connect(self.db_path)
            self.conn.row_factory = sqlite3.Row
            self.cursor = self.conn.cursor()
            return True
        except sqlite3.Error as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            return False
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        if self.conn:
            self.conn.close()
    
    # ==================== –û–°–ù–û–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ====================
    
    def get_total_stats(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        stats = {}
        
        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        self.cursor.execute("SELECT COUNT(*) FROM content")
        stats['total'] = self.cursor.fetchone()[0]
        
        # –ü–æ —Ç–∏–ø–∞–º
        self.cursor.execute("""
            SELECT type, COUNT(*) as count
            FROM content
            GROUP BY type
            ORDER BY count DESC
        """)
        stats['by_type'] = dict(self.cursor.fetchall())
        
        # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —Ç–∏–ø–∞–º
        self.cursor.execute("""
            SELECT type, ROUND(AVG(rating), 2) as avg_rating
            FROM content
            WHERE rating IS NOT NULL
            GROUP BY type
        """)
        stats['avg_rating'] = dict(self.cursor.fetchall())
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å needs_ai
        self.cursor.execute("SELECT COUNT(*) FROM content WHERE needs_ai = 1")
        stats['needs_ai'] = self.cursor.fetchone()[0]
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è
        self.cursor.execute("SELECT COUNT(*) FROM content WHERE description IS NULL OR description = ''")
        stats['no_description'] = self.cursor.fetchone()[0]
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.cursor.execute("SELECT COUNT(*) FROM content WHERE image_url IS NULL OR image_url = ''")
        stats['no_image'] = self.cursor.fetchone()[0]
        
        return stats
    
    def get_genre_stats(self, limit: int = 10) -> List[Tuple]:
        """–¢–æ–ø –∂–∞–Ω—Ä–æ–≤"""
        self.cursor.execute("""
            SELECT genre, COUNT(*) as count
            FROM content
            WHERE genre IS NOT NULL
            GROUP BY genre
            ORDER BY count DESC
            LIMIT ?
        """, (limit,))
        return self.cursor.fetchall()
    
    def get_epoch_stats(self, limit: int = 10) -> List[Tuple]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —ç–ø–æ—Ö–∞–º"""
        self.cursor.execute("""
            SELECT epoch, COUNT(*) as count
            FROM content
            WHERE epoch IS NOT NULL
            GROUP BY epoch
            ORDER BY count DESC
            LIMIT ?
        """, (limit,))
        return self.cursor.fetchall()
    
    def get_year_distribution(self) -> List[Tuple]:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º"""
        self.cursor.execute("""
            SELECT 
                CASE 
                    WHEN year >= 2020 THEN '2020s'
                    WHEN year >= 2010 THEN '2010s'
                    WHEN year >= 2000 THEN '2000s'
                    WHEN year >= 1990 THEN '90s'
                    WHEN year >= 1980 THEN '80s'
                    ELSE 'classics'
                END as decade,
                COUNT(*) as count
            FROM content
            WHERE year IS NOT NULL
            GROUP BY decade
            ORDER BY count DESC
        """)
        return self.cursor.fetchall()
    
    # ==================== –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê ====================
    
    def check_data_quality(self, content_type: str = None) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
        quality_report = {
            'missing_fields': {},
            'empty_ratings': 0,
            'duplicates': 0,
            'orphaned_records': 0
        }
        
        type_filter = f"WHERE type = '{content_type}'" if content_type else ""
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
        for field in ['title', 'creator', 'description', 'image_url', 'year', 'rating', 'genre']:
            self.cursor.execute(f"""
                SELECT COUNT(*) FROM content 
                {type_filter}
                {'AND' if content_type else 'WHERE'} ({field} IS NULL OR {field} = '')
            """)
            count = self.cursor.fetchone()[0]
            if count > 0:
                quality_report['missing_fields'][field] = count
        
        # –ü—É—Å—Ç—ã–µ —Ä–µ–π—Ç–∏–Ω–≥–∏
        self.cursor.execute(f"""
            SELECT COUNT(*) FROM content 
            {type_filter}
            {'AND' if content_type else 'WHERE'} rating IS NULL
        """)
        quality_report['empty_ratings'] = self.cursor.fetchone()[0]
        
        # –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ source_id
        self.cursor.execute(f"""
            SELECT source_id, COUNT(*) as count
            FROM content
            {type_filter}
            GROUP BY source_id
            HAVING count > 1
        """)
        quality_report['duplicates'] = len(self.cursor.fetchall())
        
        return quality_report
    
    def find_duplicates(self, limit: int = 20) -> List[Dict]:
        """–ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã"""
        self.cursor.execute("""
            SELECT title, creator, type, COUNT(*) as count, GROUP_CONCAT(id) as ids
            FROM content
            GROUP BY LOWER(title), LOWER(creator), type
            HAVING count > 1
            ORDER BY count DESC
            LIMIT ?
        """, (limit,))
        
        duplicates = []
        for row in self.cursor.fetchall():
            duplicates.append({
                'title': row[0],
                'creator': row[1],
                'type': row[2],
                'count': row[3],
                'ids': row[4]
            })
        return duplicates
    
    def find_missing_critical_data(self, content_type: str, limit: int = 20) -> List[Dict]:
        """–ù–∞–π—Ç–∏ –∑–∞–ø–∏—Å–∏ —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        if content_type not in REQUIRED_FIELDS:
            return []
        
        conditions = []
        for field in REQUIRED_FIELDS[content_type]:
            conditions.append(f"({field} IS NULL OR {field} = '')")
        
        query = f"""
            SELECT id, title, creator, type, genre, year
            FROM content
            WHERE type = ?
            AND ({' OR '.join(conditions)})
            LIMIT ?
        """
        
        self.cursor.execute(query, (content_type, limit))
        
        results = []
        for row in self.cursor.fetchall():
            results.append({
                'id': row[0],
                'title': row[1],
                'creator': row[2],
                'type': row[3],
                'genre': row[4],
                'year': row[5]
            })
        return results
    
    # ==================== –°–ü–ï–¶–ò–§–ò–ß–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ====================
    
    def get_type_specific_values(self, content_type: str) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        values = {}
        
        # –ñ–∞–Ω—Ä—ã
        self.cursor.execute("""
            SELECT DISTINCT genre FROM content
            WHERE type = ? AND genre IS NOT NULL
            ORDER BY genre
        """, (content_type,))
        values['genres'] = [row[0] for row in self.cursor.fetchall()]
        
        # –≠–ø–æ—Ö–∏
        self.cursor.execute("""
            SELECT DISTINCT epoch FROM content
            WHERE type = ? AND epoch IS NOT NULL
            ORDER BY epoch
        """, (content_type,))
        values['epochs'] = [row[0] for row in self.cursor.fetchall()]
        
        # –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏—è (–¥–ª—è –º—É–∑—ã–∫–∏)
        if content_type == 'music':
            self.cursor.execute("""
                SELECT DISTINCT mood FROM content
                WHERE type = 'music' AND mood IS NOT NULL
                ORDER BY mood
            """)
            values['moods'] = [row[0] for row in self.cursor.fetchall()]
        
        return values
    
    # ==================== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ====================
    
    def generate_recommendations(self) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ë–î"""
        recommendations = []
        
        stats = self.get_total_stats()
        quality = self.check_data_quality()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ needs_ai
        if stats['needs_ai'] > 0:
            percentage = (stats['needs_ai'] / stats['total']) * 100
            recommendations.append(
                f"ü§ñ {stats['needs_ai']} –∑–∞–ø–∏—Å–µ–π ({percentage:.1f}%) –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ AI-–æ–ø–∏—Å–∞–Ω–∏—è—Ö. "
                f"–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python scripts/tools/ai_describer.py --limit=100"
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π
        if stats['no_description'] > 500:
            recommendations.append(
                f"üìù {stats['no_description']} –∑–∞–ø–∏—Å–µ–π –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è. "
                f"–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–π—Ç–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å –≤—ã—Å–æ–∫–∏–º —Ä–µ–π—Ç–∏–Ω–≥–æ–º."
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if stats['no_image'] > 1000:
            recommendations.append(
                f"üñºÔ∏è {stats['no_image']} –∑–∞–ø–∏—Å–µ–π –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. "
                f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ API-–∫–ª—é—á–∏ –¥–ª—è Google Books, TMDB, Spotify."
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        duplicates = self.find_duplicates(limit=5)
        if len(duplicates) > 0:
            recommendations.append(
                f"üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(duplicates)} –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤. "
                f"–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python scripts/migrations/fix_duplicates.py"
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ —Ç–∏–ø–∞–º
        for content_type in ['book', 'movie', 'music']:
            missing = self.find_missing_critical_data(content_type, limit=1)
            if len(missing) > 0:
                recommendations.append(
                    f"‚ö†Ô∏è –¢–∏–ø '{content_type}': –Ω–∞–π–¥–µ–Ω—ã –∑–∞–ø–∏—Å–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–ª—è–º–∏. "
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∫—Ä–∏–ø—Ç—ã —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö."
                )
        
        return recommendations
    
    # ==================== –í–´–í–û–î –û–¢–ß–ï–¢–û–í ====================
    
    def print_full_report(self):
        """–í—ã–≤–µ—Å—Ç–∏ –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å"""
        print("\n" + "=" * 70)
        print("üîç DATABASE INSPECTOR - –ü–û–õ–ù–´–ô –û–¢–ß–ï–¢".center(70))
        print("=" * 70)
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = self.get_total_stats()
        print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print(f"{'‚îÄ' * 70}")
        print(f"üìö –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total']:,}")
        print(f"\nüìã –ü–æ —Ç–∏–ø–∞–º:")
        for content_type, count in stats['by_type'].items():
            emoji = EMOJI_MAP.get(content_type, 'üìÑ')
            avg_rating = stats['avg_rating'].get(content_type, 0)
            print(f"  {emoji} {content_type.capitalize()}: {count:,} (‚≠ê {avg_rating})")
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        print(f"\nüéØ –ö–ê–ß–ï–°–¢–í–û –î–ê–ù–ù–´–•")
        print(f"{'‚îÄ' * 70}")
        print(f"‚ö° –ù—É–∂–Ω–æ AI-–æ–ø–∏—Å–∞–Ω–∏–π: {stats['needs_ai']:,}")
        print(f"üìù –ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è: {stats['no_description']:,}")
        print(f"üñºÔ∏è –ë–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {stats['no_image']:,}")
        
        # –¢–æ–ø –∂–∞–Ω—Ä–æ–≤
        print(f"\nüé≠ –¢–û–ü-10 –ñ–ê–ù–†–û–í")
        print(f"{'‚îÄ' * 70}")
        for i, (genre, count) in enumerate(self.get_genre_stats(10), 1):
            print(f"  {i:2}. {genre:20} {count:,}")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º
        print(f"\nüìÖ –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –≠–ü–û–•–ê–ú")
        print(f"{'‚îÄ' * 70}")
        for decade, count in self.get_year_distribution():
            print(f"  {decade:15} {count:,}")
        
        # –ü—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞
        print(f"\n‚ö†Ô∏è –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê")
        print(f"{'‚îÄ' * 70}")
        quality = self.check_data_quality()
        
        if quality['missing_fields']:
            print("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –ø–æ–ª—è:")
            for field, count in quality['missing_fields'].items():
                print(f"  - {field:15} {count:,} –∑–∞–ø–∏—Å–µ–π")
        
        if quality['duplicates'] > 0:
            print(f"\nüîÑ –î—É–±–ª–∏–∫–∞—Ç—ã: {quality['duplicates']} –≥—Ä—É–ø–ø")
            duplicates = self.find_duplicates(5)
            for dup in duplicates[:3]:
                print(f"  - '{dup['title']}' by {dup['creator']} ({dup['count']} –∫–æ–ø–∏–π)")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = self.generate_recommendations()
        if recommendations:
            print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ({len(recommendations)})")
            print(f"{'‚îÄ' * 70}")
            for i, rec in enumerate(recommendations, 1):
                print(f"{i}. {rec}\n")
        
        print("=" * 70)
        print(f"‚úÖ –û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70 + "\n")
    
    def print_type_report(self, content_type: str):
        """–û—Ç—á–µ—Ç –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ç–∏–ø—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        if content_type not in ['book', 'movie', 'music']:
            print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø: {content_type}")
            return
        
        emoji = EMOJI_MAP[content_type]
        print(f"\n{emoji} –û–¢–ß–ï–¢ –ü–û –¢–ò–ü–£: {content_type.upper()}")
        print("=" * 70)
        
        # –û–±—â–∏–µ —Ü–∏—Ñ—Ä—ã
        self.cursor.execute("SELECT COUNT(*) FROM content WHERE type = ?", (content_type,))
        total = self.cursor.fetchone()[0]
        print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total:,}")
        
        # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥
        self.cursor.execute("""
            SELECT ROUND(AVG(rating), 2) FROM content 
            WHERE type = ? AND rating IS NOT NULL
        """, (content_type,))
        avg_rating = self.cursor.fetchone()[0]
        print(f"–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: ‚≠ê {avg_rating or 0}")
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        values = self.get_type_specific_values(content_type)
        print(f"\nüìÇ –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
        print(f"  –ñ–∞–Ω—Ä—ã ({len(values['genres'])}): {', '.join(values['genres'][:10])}")
        if values['epochs']:
            print(f"  –≠–ø–æ—Ö–∏ ({len(values['epochs'])}): {', '.join(values['epochs'][:10])}")
        if 'moods' in values:
            print(f"  –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏—è ({len(values['moods'])}): {', '.join(values['moods'][:10])}")
        
        # –ü—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞
        quality = self.check_data_quality(content_type)
        print(f"\n‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞:")
        for field, count in quality['missing_fields'].items():
            if count > 0:
                percentage = (count / total) * 100
                print(f"  - {field:15} {count:,} ({percentage:.1f}%)")
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–ø—É—Å–∫–∏
        missing = self.find_missing_critical_data(content_type, 5)
        if missing:
            print(f"\nüö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–ø—É—Å–∫–∏ (—Ç–æ–ø-5):")
            for item in missing:
                print(f"  ID {item['id']:5} | {item['title'][:40]:40} | {item['creator'] or 'N/A'}")
        
        print("=" * 70 + "\n")
    
    def export_json(self, filename: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –≤ JSON"""
        report = {
            'generated_at': datetime.now().isoformat(),
            'database': self.db_path,
            'stats': self.get_total_stats(),
            'quality': self.check_data_quality(),
            'duplicates': self.find_duplicates(50),
            'recommendations': self.generate_recommendations()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
    
    def export_csv(self, filename: str, content_type: str = None):
        """–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ CSV"""
        type_filter = f"WHERE type = '{content_type}'" if content_type else ""
        
        self.cursor.execute(f"""
            SELECT id, type, title, creator, genre, year, rating,
                   CASE WHEN description IS NULL OR description = '' THEN 'YES' ELSE 'NO' END as missing_desc,
                   CASE WHEN image_url IS NULL OR image_url = '' THEN 'YES' ELSE 'NO' END as missing_image,
                   needs_ai
            FROM content
            {type_filter}
        """)
        
        rows = self.cursor.fetchall()
        
        with open(filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['ID', 'Type', 'Title', 'Creator', 'Genre', 'Year', 'Rating', 
                           'Missing Desc', 'Missing Image', 'Needs AI'])
            writer.writerows(rows)
        
        print(f"‚úÖ CSV —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω: {filename} ({len(rows)} –∑–∞–ø–∏—Å–µ–π)")

# ==================== CLI ====================

def main():
    parser = argparse.ArgumentParser(
        description='üîç DB Inspector - –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ë–î',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python db_inspector.py                          # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
  python db_inspector.py --type books             # –û—Ç—á–µ—Ç –ø–æ –∫–Ω–∏–≥–∞–º
  python db_inspector.py --type music             # –û—Ç—á–µ—Ç –ø–æ –º—É–∑—ã–∫–µ
  python db_inspector.py --missing-data           # –¢–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –∑–∞–ø–∏—Å–∏
  python db_inspector.py --duplicates             # –ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã
  python db_inspector.py --export-json report.json
  python db_inspector.py --export-csv data.csv --type movies
        """
    )
    
    parser.add_argument('--type', 
                       choices=['books', 'movies', 'music'],
                       help='–¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞')
    
    parser.add_argument('--missing-data',
                       action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏')
    
    parser.add_argument('--duplicates',
                       action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã')
    
    parser.add_argument('--export-json',
                       metavar='FILE',
                       help='–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –≤ JSON')
    
    parser.add_argument('--export-csv',
                       metavar='FILE',
                       help='–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ CSV')
    
    parser.add_argument('--db',
                       default=DB_PATH,
                       help=f'–ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {DB_PATH})')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä
    inspector = DatabaseInspector(args.db)
    
    if not inspector.connect():
        sys.exit(1)
    
    try:
        # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã
        if args.export_json:
            inspector.export_json(args.export_json)
        
        elif args.export_csv:
            content_type = args.type[:-1] if args.type else None  # books -> book
            inspector.export_csv(args.export_csv, content_type)
        
        elif args.duplicates:
            print("\nüîÑ –ü–û–ò–°–ö –î–£–ë–õ–ò–ö–ê–¢–û–í")
            print("=" * 70)
            duplicates = inspector.find_duplicates(50)
            if duplicates:
                for i, dup in enumerate(duplicates, 1):
                    print(f"{i:2}. '{dup['title']}' by {dup['creator']}")
                    print(f"    –¢–∏–ø: {dup['type']} | –ö–æ–ø–∏–π: {dup['count']} | IDs: {dup['ids']}\n")
            else:
                print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        
        elif args.missing_data:
            print("\n‚ö†Ô∏è –ó–ê–ü–ò–°–ò –° –ü–†–û–ü–£–©–ï–ù–ù–´–ú–ò –î–ê–ù–ù–´–ú–ò")
            print("=" * 70)
            for content_type in ['book', 'movie', 'music']:
                missing = inspector.find_missing_critical_data(content_type, 10)
                if missing:
                    emoji = EMOJI_MAP[content_type]
                    print(f"\n{emoji} {content_type.upper()} ({len(missing)} –∑–∞–ø–∏—Å–µ–π):")
                    for item in missing:
                        print(f"  ID {item['id']:5} | {item['title'][:50]}")
        
        elif args.type:
            content_type = args.type[:-1]  # books -> book
            inspector.print_type_report(content_type)
        
        else:
            # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            inspector.print_full_report()
    
    finally:
        inspector.close()

if __name__ == "__main__":
    main()
